{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mini Project 2",
      "provenance": [],
      "collapsed_sections": [
        "CHXVmswSXiJ-",
        "Er0O_nphXsaN"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junelsolis/AAU-Machine-Learning/blob/main/Mini_Project_2_later.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHXVmswSXiJ-"
      },
      "source": [
        "# Initial setup and data import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb0d3bM_EmUi",
        "outputId": "398d3773-576f-4288-d697-8578e46de2d0"
      },
      "source": [
        "!pip install tweet-preprocessor nltk keras-tuner\n",
        "!pip install tqdm>=4.9.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (1.0.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=0648e1258e69c968eb91b2d3ba7464ed3eea703c73b57f9fa500d61a183e1e7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=4a15f06b8ecc00834d1b4c1696653432a375bad5e7d7bcb4dd87c2d86b032513\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: tweet-preprocessor, terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0 tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju-bNGEZGtZj",
        "outputId": "06722992-216a-489d-8f6d-acfc4d28f84c"
      },
      "source": [
        "# Mount Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvT_XJ8AEkZk"
      },
      "source": [
        "# Make default library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import preprocessor as p\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FpDgEYIfEkZm",
        "outputId": "59dd0d9a-3452-4cc8-ba6b-407ec9786ddf"
      },
      "source": [
        "# Read the data from file\n",
        "data = pd.read_csv('/content/drive/MyDrive/AAU-Machine-Learning/Mini-Project-2/Sentiment140.tenPercent.sample.tweets.tsv', delimiter='\\t')\n",
        "data.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment_label</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>@elephantbird Hey dear, Happy Friday to You  A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Ughhh layin downnnn    Waiting for zeina to co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@greeniebach I reckon he'll play, even if he's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@vaLewee I know!  Saw it on the news!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>very sad that http://www.fabchannel.com/ has c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment_label                                         tweet_text\n",
              "0                4  @elephantbird Hey dear, Happy Friday to You  A...\n",
              "1                4  Ughhh layin downnnn    Waiting for zeina to co...\n",
              "2                0  @greeniebach I reckon he'll play, even if he's...\n",
              "3                0              @vaLewee I know!  Saw it on the news!\n",
              "4                0  very sad that http://www.fabchannel.com/ has c..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "V5i_CXRhEkZn",
        "outputId": "deea6f62-f67d-4dab-83fd-1f04ff8cb86f"
      },
      "source": [
        "# Check for null values in the data\n",
        "# Plot label histogram\n",
        "print('Null values present in labels: ' + str(data['sentiment_label'].isnull().values.any()))\n",
        "print('Null values present in tweet text: ' + str(data['tweet_text'].isnull().values.any()))\n",
        "print()\n",
        "\n",
        "plt.title('Distribution of sentiment values')\n",
        "plt.bar(['0','4'], [len(data['sentiment_label'].where(data['sentiment_label'] == 0)), len(data['sentiment_label'].where(data['sentiment_label'] == 4))])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null values present in labels: False\n",
            "Null values present in tweet text: False\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 2 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er0O_nphXsaN"
      },
      "source": [
        "# Preprocess tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDlY9m0aXWPq",
        "outputId": "0dfbfbfa-5517-407f-cb34-f6c3925b8901"
      },
      "source": [
        "# Import NLTK dependencies\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Spacy dependencies\n",
        "# import spacy\n",
        "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rouefPEsrskV",
        "outputId": "12390eb5-5685-4ded-c92f-4940760bc684"
      },
      "source": [
        "!pip install textblob\n",
        "from textblob import TextBlob, Word"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXu39rKt32hb"
      },
      "source": [
        "### Text processing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zWsbN6m38Q6"
      },
      "source": [
        "def process_tweet(tweet):\n",
        "\n",
        "  clean_tweet = p.clean(tweet)\n",
        "  # Remove punctuations and numbers\n",
        "  clean_tweet = re.sub('[^a-zA-Z]', ' ', clean_tweet)\n",
        "\n",
        "  # Convert to lower case\n",
        "  clean_tweet = clean_tweet.lower()\n",
        "\n",
        "  # Single character removal\n",
        "  clean_tweet = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', clean_tweet)\n",
        "\n",
        "  # Removing multiple spaces\n",
        "  clean_tweet = re.sub(r'\\s+', ' ', clean_tweet)\n",
        "\n",
        "  # Remove words longer\n",
        "  clean_tweet_words = clean_tweet.split(' ')\n",
        "  filter_max_word_length_tweet = []\n",
        "  for w in clean_tweet_words:\n",
        "    if (len(w) <= 40):\n",
        "      filter_max_word_length_tweet.append(w)\n",
        "\n",
        "  clean_tweet =  \" \".join(filter_max_word_length_tweet)\n",
        "\n",
        "  # Remove multiple spaces again\n",
        "  clean_tweet = re.sub(r'\\s+', ' ', clean_tweet)\n",
        "  return clean_tweet\n",
        "\n",
        "\n",
        "tag_dict = {\"J\": 'a', \n",
        "            \"N\": 'n', \n",
        "            \"V\": 'v', \n",
        "            \"R\": 'r'}\n",
        "\n",
        "def lemmatize(tweet):\n",
        "  blob = TextBlob(tweet)\n",
        "\n",
        "  \n",
        "  words_and_tags = [(Word(w), tag_dict.get(pos[0], 'n')) for w, pos in blob.tags]\n",
        "  lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
        "\n",
        "  return \" \".join(lemmatized_list)\n",
        "\n",
        "\n",
        "def remove_stop_words(tweet):\n",
        "\n",
        "  word_tokens = word_tokenize(tweet)  \n",
        "  \n",
        "  filtered_sentence = []  \n",
        "    \n",
        "  for w in word_tokens:  \n",
        "      if w not in stop_words:  \n",
        "          filtered_sentence.append(w)  \n",
        "\n",
        "  return \" \".join(filtered_sentence)\n",
        "\n",
        "\n",
        "def empty_single_word_tweets(tweet):\n",
        "    if (len(tweet.split(' ')) > 1):\n",
        "        return tweet\n",
        "    else:\n",
        "        return ''\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK3voncCEkZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7247b57e-9cd7-4e9c-9d72-1a9c1911fa4d"
      },
      "source": [
        "# Clean the tweets. \n",
        "# Remove the following:\n",
        "# - URLS\n",
        "# - Hashtags\n",
        "# - Mentions\n",
        "# - Reserved words (RT, FAV)\n",
        "# - Emojis\n",
        "# - Smileys\n",
        "# - Numbers\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "# Copy the dataset and retain the original data\n",
        "clean_data = data.copy()\n",
        "clean_data = clean_data.sample(70000) # reduce number of samples\n",
        "\n",
        "# Convert labels to binary\n",
        "clean_data.loc[clean_data['sentiment_label'] == 4, 'sentiment_label'] = 1\n",
        "\n",
        "\n",
        "index = random.randrange(0, len(clean_data.index) - 1)\n",
        "\n",
        "# Run tweet preprocessor for cleaning\n",
        "clean_data['tweet_text'] = clean_data['tweet_text'].progress_apply(lambda row: process_tweet(row))\n",
        "\n",
        "# Lemmatize\n",
        "clean_data['tweet_text'] = clean_data['tweet_text'].progress_apply(lambda row: lemmatize(row))\n",
        "\n",
        "# Remove stop words\n",
        "clean_data['tweet_text'] = clean_data['tweet_text'].progress_apply(lambda row: remove_stop_words(row))\n",
        "\n",
        "# Remove tweets with only a single word\n",
        "clean_data['tweet_text'] = clean_data['tweet_text'].progress_apply(lambda row: empty_single_word_tweets(row))\n",
        "clean_data.drop(clean_data[clean_data['tweet_text'] == ''].index, inplace=True)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [00:08<00:00, 8123.18it/s]\n",
            "100%|██████████| 70000/70000 [01:12<00:00, 959.43it/s]\n",
            "100%|██████████| 70000/70000 [00:07<00:00, 9224.43it/s]\n",
            "100%|██████████| 70000/70000 [00:00<00:00, 610390.06it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG52ExC8WHxr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "f05521d8-e000-42cd-8030-4f5ab934a009"
      },
      "source": [
        "# Print random sample of cleaned tweets\n",
        "clean_data.sample(15)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment_label</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60215</th>\n",
              "      <td>0</td>\n",
              "      <td>miss jon already</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48431</th>\n",
              "      <td>0</td>\n",
              "      <td>come home dog torn screen miss cat check basem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95719</th>\n",
              "      <td>1</td>\n",
              "      <td>would listen xoxo derek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138162</th>\n",
              "      <td>1</td>\n",
              "      <td>pierwszy tyg finalow za mna uff mocno bylo ter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28922</th>\n",
              "      <td>0</td>\n",
              "      <td>go roll call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30475</th>\n",
              "      <td>0</td>\n",
              "      <td>want go home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112538</th>\n",
              "      <td>1</td>\n",
              "      <td>let hope go well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148518</th>\n",
              "      <td>1</td>\n",
              "      <td>know exactly much despise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119908</th>\n",
              "      <td>1</td>\n",
              "      <td>canadaaaa lovely day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15295</th>\n",
              "      <td>1</td>\n",
              "      <td>rise wed favor tag thanks stephen purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46542</th>\n",
              "      <td>1</td>\n",
              "      <td>ooops misread message mention u another tweete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111434</th>\n",
              "      <td>1</td>\n",
              "      <td>every single place world mean need go pushed e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83438</th>\n",
              "      <td>1</td>\n",
              "      <td>purchase educate app iphone report come soon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97979</th>\n",
              "      <td>0</td>\n",
              "      <td>really feed already home boring bad time beth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17030</th>\n",
              "      <td>1</td>\n",
              "      <td>nice unfortunately probably cant wish power</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment_label                                         tweet_text\n",
              "60215                 0                                   miss jon already\n",
              "48431                 0  come home dog torn screen miss cat check basem...\n",
              "95719                 1                            would listen xoxo derek\n",
              "138162                1  pierwszy tyg finalow za mna uff mocno bylo ter...\n",
              "28922                 0                                       go roll call\n",
              "30475                 0                                       want go home\n",
              "112538                1                                   let hope go well\n",
              "148518                1                          know exactly much despise\n",
              "119908                1                               canadaaaa lovely day\n",
              "15295                 1         rise wed favor tag thanks stephen purchase\n",
              "46542                 1  ooops misread message mention u another tweete...\n",
              "111434                1  every single place world mean need go pushed e...\n",
              "83438                 1       purchase educate app iphone report come soon\n",
              "97979                 0      really feed already home boring bad time beth\n",
              "17030                 1        nice unfortunately probably cant wish power"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asC2-ajYnXQm"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuxcYn2JIIxt"
      },
      "source": [
        "## Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsoXgasnnccd"
      },
      "source": [
        "# Split the dataset into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(clean_data['tweet_text'], clean_data['sentiment_label'], test_size=0.2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOebQbV4Igi7"
      },
      "source": [
        "## Vectorize using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8zot3Xx14-t"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf_idf_vect = TfidfVectorizer(max_features=5000)\n",
        "tf_idf_vect.fit(clean_data['tweet_text'])\n",
        "\n",
        "X_train_tf_idf = tf_idf_vect.transform(X_train)\n",
        "X_test_tf_idf = tf_idf_vect.transform(X_test)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtYqQjFyIrmT"
      },
      "source": [
        "## Fit data to SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx71da3I7ULV",
        "outputId": "505f4926-56f9-4f42-d872-3d4b30decad2"
      },
      "source": [
        "from sklearn import model_selection, naive_bayes, svm\n",
        "\n",
        "\n",
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', verbose=True)\n",
        "SVM.fit(X_train_tf_idf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyrbctgyIx2A"
      },
      "source": [
        "## Measure accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFF8NI8yI5CC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "cbb8fdf9-0565-4d07-da69-854e873c8237"
      },
      "source": [
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(X_test_tf_idf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-abceedd46426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# predict the labels on validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions_SVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tf_idf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Use accuracy_score function to get the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVM Accuracy Score -> \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_SVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SVM' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnINm1KZYB1s"
      },
      "source": [
        "# LSTM/RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z9ya07VKDBZ"
      },
      "source": [
        "## Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c15JmcqWLKn1"
      },
      "source": [
        "# Tokenize the text corpus\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, split=\" \")\n",
        "tokenizer.fit_on_texts(clean_data['tweet_text'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(clean_data['tweet_text'].values)\n",
        "X = pad_sequences(X) # padding our text vector so they all have the same length"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcpFzYljKB98"
      },
      "source": [
        "# Split the dataset into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X, clean_data['sentiment_label'], test_size=0.2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wovCQ9-mKdgt"
      },
      "source": [
        "### Configure hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4FZAkbUEkZp"
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    hp_units_embed = hp.Int('units_embed', min_value = 32, max_value = 512, step = 32)\n",
        "    model.add(Embedding(5000, hp_units_embed, input_length=X.shape[1]))\n",
        "\n",
        "    hp_units_1 = hp.Int('units_1', min_value = 32, max_value = 512, step = 32)\n",
        "    model.add(LSTM(hp_units_1, return_sequences = True, dropout = 0.3, recurrent_dropout = 0.2))\n",
        "    \n",
        "    hp_units_2 = hp.Int('units_2', min_value = 32, max_value = 512, step = 32)\n",
        "    model.add(LSTM(hp_units_2, dropout=0.3, recurrent_dropout=0.2))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Tune the learning rate for the optimizer \n",
        "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd']) \n",
        "\n",
        "    model.compile(loss=SparseCategoricalCrossentropy(), optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5LrDp1oEkZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb53e56-9ddd-4cee-c8c9-fd2e2ac85741"
      },
      "source": [
        "import kerastuner as kt\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "\n",
        "lstm_tuner = kt.Hyperband(build_model,\n",
        "                     objective = 'val_accuracy', \n",
        "                     max_epochs = 12,\n",
        "                     factor = 3,\n",
        "                     directory = '/content/drive/MyDrive/AAU-Machine-Learning/',\n",
        "                     project_name = 'Mini-Project-2')\n",
        "\n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)\n",
        "\n",
        "lstm_tuner.search(X_train_lstm, y_train_lstm, epochs = 5, validation_split=0.3, callbacks = [ClearTrainingOutput()])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = lstm_tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 08m 47s]\n",
            "val_accuracy: 0.5046549439430237\n",
            "\n",
            "Best val_accuracy So Far: 0.5046549439430237\n",
            "Total elapsed time: 00h 08m 47s\n",
            "\n",
            "Search: Running Trial #2\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "units             |320               |416               \n",
            "learning_rate     |0.01              |0.01              \n",
            "optimizer         |adam              |sgd               \n",
            "units_embed       |480               |32                \n",
            "units_1           |224               |32                \n",
            "units_2           |32                |32                \n",
            "tuner/epochs      |2                 |2                 \n",
            "tuner/initial_e...|0                 |0                 \n",
            "tuner/bracket     |2                 |2                 \n",
            "tuner/round       |0                 |0                 \n",
            "\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/2\n",
            " 954/1175 [=======================>......] - ETA: 52s - loss: 0.5931 - accuracy: 0.6712"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOmlRMyiRaND"
      },
      "source": [
        "# Compile and train model\n",
        "# model = tuner.hypermodel.build(best_hps)\n",
        "# history = model.fit(X_train, y_train, epochs = 6, validation_split=0.3)\n",
        "# model.save('lstm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRqAnjrlRZu_"
      },
      "source": [
        ""
      ]
    }
  ]
}